{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3221e21e",
   "metadata": {},
   "source": [
    "# CityStreetFlow: QUBO-ML Traffic Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import dimod\n",
    "import dynex\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad810d",
   "metadata": {},
   "source": [
    "### Loading/Analyzing district using [OSM] OpenStreetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ee585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_speed_limit(speed_limit):\n",
    "    match = re.search(r'\\d+', speed_limit)\n",
    "    if match:\n",
    "        return int(match.group())  \n",
    "    return None  \n",
    "\n",
    "def ExtractInfo(graph, edgeColors):\n",
    "    junctionNodes = []\n",
    "    df = pd.DataFrame(columns=[\"RoadType\", \"SpeedLimit\", \"NodeID\", \"x\", \"y\"])\n",
    "    for u, v, k, data in graph.edges(keys=True, data=True):\n",
    "        if 'highway' in data:\n",
    "            roadType = data['highway'][0] if isinstance(data['highway'], list) else data['highway']\n",
    "            speedLimit = data.get('maxspeed', 'No data')\n",
    "            if isinstance(speedLimit, list):\n",
    "                speedLimit = speedLimit[0]\n",
    "            if 'mph' in speedLimit or isinstance(speedLimit, str) and speedLimit.isdigit():\n",
    "                speedLimit = parse_speed_limit(speedLimit)\n",
    "            for _, _, d in graph.out_edges(u, data=True):\n",
    "                neighborRoadType = d['highway'][0] if isinstance(d['highway'], list) else d['highway']\n",
    "                if neighborRoadType != roadType and u not in [node[0] for node in junctionNodes]:\n",
    "                    junctionNodes.append((u, roadType, speedLimit))\n",
    "                    new_row = pd.DataFrame({\n",
    "                        \"RoadType\": [roadType],\n",
    "                        \"SpeedLimit\": [speedLimit],\n",
    "                        \"NodeID\": [u],\n",
    "                        \"x\": [graph.nodes[u]['x']],\n",
    "                        \"y\": [graph.nodes[u]['y']]\n",
    "                    })\n",
    "                    df = pd.concat([df, new_row], ignore_index=True)\n",
    "            for _, _, d in graph.out_edges(v, data=True):\n",
    "                neighborRoadType = d['highway'][0] if isinstance(d['highway'], list) else d['highway']\n",
    "                if neighborRoadType != roadType and v not in [node[0] for node in junctionNodes]:\n",
    "                    junctionNodes.append((v, roadType, speedLimit))\n",
    "                    new_row = pd.DataFrame({\n",
    "                        \"RoadType\": [roadType],\n",
    "                        \"SpeedLimit\": [speedLimit],\n",
    "                        \"NodeID\": [v],\n",
    "                        \"x\": [graph.nodes[v]['x']],\n",
    "                        \"y\": [graph.nodes[v]['y']]\n",
    "                    })\n",
    "                    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_csv('speedLimit_.csv', index=False)\n",
    "    return junctionNodes\n",
    "\n",
    "def LoadPlot(placeName):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\") #I'm using old version of OSM API, even though I couldn't disable all warnings lol\n",
    "        fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "        ax.set_facecolor('white')\n",
    "        graph = ox.graph_from_place(placeName)\n",
    "        buildings = ox.geometries_from_place(placeName, tags={'building': True})\n",
    "        plots = ox.features_from_place(placeName, tags={'landuse': True})\n",
    "        \n",
    "        edgeColors = {\n",
    "            'motorway': 'red',\n",
    "            'primary': 'orange',\n",
    "            'secondary': 'yellow'} # you can include all road types, but this example is just a showcase\n",
    "        for u, v, k, data in graph.edges(keys=True, data=True):\n",
    "            if 'highway' in data:\n",
    "                roadType = data['highway'][0] if isinstance(data['highway'], list) else data['highway']\n",
    "                color = edgeColors.get(roadType, 'gray')\n",
    "                x1, y1 = graph.nodes[u]['x'], graph.nodes[u]['y']\n",
    "                x2, y2 = graph.nodes[v]['x'], graph.nodes[v]['y']\n",
    "                ax.plot([x1, x2], [y1, y2], color=color, linewidth=1, alpha=0.8)        \n",
    "        buildings.plot(ax=ax, facecolor='khaki', alpha=1.0)\n",
    "        plots.plot(ax=ax, facecolor='green', alpha=0.5)\n",
    "        junctionNodes = ExtractInfo(graph, edgeColors)\n",
    "        for node, roadType, speedLimit in junctionNodes:\n",
    "            color = 'aqua' if speedLimit == 'No data' else ('red' if int(speedLimit) >= 40 else 'purple')\n",
    "            ax.scatter(graph.nodes[node]['x'], graph.nodes[node]['y'], c=color, s=20, zorder=3)\n",
    "        legendElements = [\n",
    "            mlines.Line2D([], [], color='orange', label='Primary Road'),\n",
    "            mlines.Line2D([], [], color='yellow', label='Secondary Road'),\n",
    "            mlines.Line2D([], [], color='gray', label='OtherRoads/Ave'),\n",
    "            mlines.Line2D([], [], color='khaki', label='Buildings', linewidth=10),\n",
    "            mlines.Line2D([], [], color='green', label='Plots', linewidth=10),\n",
    "            mlines.Line2D([], [], color='red', marker='o', markersize=5, label='Junctions (SPEED >=40)', linewidth=0),\n",
    "            mlines.Line2D([], [], color='purple', marker='o', markersize=5, label='Junctions (SPEED <40)', linewidth=0),\n",
    "            mlines.Line2D([], [], color='aqua', marker='o', markersize=5, label='Cycleway/Pedestrian', linewidth=0)\n",
    "        ]\n",
    "        ax.legend(handles=legendElements, loc='upper left')\n",
    "        plt.show()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824e5de",
   "metadata": {},
   "source": [
    "#### [NOTE]: this is a heavy processing phase, it may take up to 5 minutes\n",
    "#### [WARNING]: if you try to load a whole city, then you need at least over 1GB memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"District/Area, City, Country\"\n",
    "#placeName = \"City of London, London, England, UK\" \n",
    "placeName = \"Ramsgate, Kent, UK\"\n",
    "graph = LoadPlot(placeName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f86e6",
   "metadata": {},
   "source": [
    "### Calculating Traffic Stress based on specific weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateStress(edgeData, weights):\n",
    "    roadType = edgeData['highway']\n",
    "    if isinstance(roadType, list):\n",
    "        roadType = roadType[0]\n",
    "    stressLevel = weights['roadType'].get(roadType, 0)\n",
    "    speedLimit = edgeData.get('maxspeed', 'No data')\n",
    "    if isinstance(speedLimit, list):\n",
    "        speedLimit = speedLimit[0]  \n",
    "    try:\n",
    "        speedLimit = int(speedLimit)\n",
    "        if speedLimit > 50:\n",
    "            stressLevel += weights['speedLimit']\n",
    "    except ValueError:\n",
    "        pass  # speedLimit is not a number which means \"no data\" which means also it's either cycleways/footways/pedestrian\n",
    "    return stressLevel\n",
    "\n",
    "def ApplyStressToGraph(graph, weights):\n",
    "    for u, v, k, data in graph.edges(data=True, keys=True):\n",
    "        data['stress'] = CalculateStress(data, weights)\n",
    "    return graph\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'roadType': {\n",
    "        'motorway': 10,\n",
    "        'primary': 5,\n",
    "        'secondary': 3,\n",
    "        'tertiary': 3,\n",
    "        'cycleway': 0,\n",
    "        'footway': 0,\n",
    "        'residential': 3,\n",
    "    },\n",
    "    'speedLimit': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ApplyStressToGraph(graph, weights)\n",
    "ec = ox.plot.get_edge_colors_by_attr(graph, 'stress', cmap='plasma', num_bins=5)\n",
    "fig, ax = ox.plot_graph(graph, edge_color=ec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf8d20",
   "metadata": {},
   "source": [
    "### Find the optimal nodes positioning by Minimizing Stress & Prioritizing Compactness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014a5fb",
   "metadata": {},
   "source": [
    "E=A∑ i​ (p i​−P i​)2+B∑j​(sj​−Sj​)2+C∑i,j​pi​sj​Dij​\n",
    " \n",
    "\n",
    "Here:\n",
    "\n",
    "A,B,C: Weights to control the importance of different terms.\n",
    "\n",
    "Pi​: Desired or optimal positioning of nodes (may depend on external factors).\n",
    "\n",
    "Sj​ : Desired or optimal speed limit (may depend on external factors).\n",
    "\n",
    "Dij​: Matrix representing the impact of placing a node at position i on a road segment with speed limit j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a12917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConstructQuboModel(graph, weights, aWeight, bWeight, distanceThreshold=None, stressThreshold=None):\n",
    "    nodeCoordsData = [(node, data['x'], data['y']) for node, data in graph.nodes(data=True)]\n",
    "    edgeStressData = [(u, v, data['stress']) for u, v, data in graph.edges(data=True)]\n",
    "    linearTerms = {\n",
    "        node: aWeight * sum(data for u, v, data in edgeStressData if u == node or v == node)\n",
    "        for node, x, y in nodeCoordsData}\n",
    "    quadraticTerms = {}\n",
    "    for (nodeI, xI, yI) in nodeCoordsData:\n",
    "        for (nodeJ, xJ, yJ) in nodeCoordsData:\n",
    "            if nodeI != nodeJ:\n",
    "                distance = np.linalg.norm(np.array((xI, yI)) - np.array((xJ, yJ)))\n",
    "                if (distanceThreshold is None or distance <= distanceThreshold) and \\\n",
    "                   (stressThreshold is None or (linearTerms[nodeI] > stressThreshold and linearTerms[nodeJ] > stressThreshold)):\n",
    "                    quadraticTerms[(nodeI, nodeJ)] = bWeight * linearTerms[nodeI] * linearTerms[nodeJ] * distance\n",
    "    #print(quadraticTerms)\n",
    "    #print(linearTerms)\n",
    "    #saveTermsToFile(linearTerms, \"linearTerms.txt\") # Just for Testing & Debugging\n",
    "    #saveTermsToFile(quadraticTerms, \"quadraticTerms.txt\") # Just for Testing & Debugging\n",
    "    \n",
    "    bqm = dimod.BinaryQuadraticModel(linearTerms, quadraticTerms, offset=0.0, vartype=dimod.BINARY)\n",
    "    \n",
    "    return bqm\n",
    "    \n",
    "def sampleQuboSolution(bqm):\n",
    "    sampler = dimod.SimulatedAnnealingSampler()\n",
    "    sampleset = sampler.sample(bqm, num_reads=1)\n",
    "    return sampleset.first.sample\n",
    "\n",
    "def dynexQuboSolution(bqm):\n",
    "    model = dynex.BQM(bqm)\n",
    "    sampler = dynex.DynexSampler(model, mainnet=False, description='Street Traffic Optimizer')\n",
    "    sampleset = sampler.sample(num_reads=100, annealing_time = 100, debugging=False);\n",
    "    return sampleset.first.sample;\n",
    "\n",
    "def saveTermsToFile(terms, filename):\n",
    "    strTerms = {str(key): value for key, value in terms.items()}\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(strTerms, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could take up to 60 sec\n",
    "a, b = 10.0, 1.0\n",
    "## [DANGER ZONE]: now since we are analyzing all different type of roads (junctionNodes), quadratic terms become more\n",
    "## and more complex and may end up with terms that are larger than 500 MB. \n",
    "## so I had to make some conditions to minimize these terms.(OPTIONAL)\n",
    "## if you want the whole quadratic terms just assign \"None\" to [distanceThreshold,stressThreshold]\n",
    "\n",
    "distanceThreshold = 1000  # Maximum distance between nodes to create a quadratic term (m)\n",
    "stressThreshold = 5       # Minimum stress level for nodes to be included in quadratic terms (checkWeights)\n",
    "bqm = ConstructQuboModel(graph, weights, a, b, distanceThreshold, stressThreshold)\n",
    "# bqm2 = constructQuboModel(graph, weights, aWeight2, bWeight2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b390b",
   "metadata": {},
   "source": [
    "if you want to test running this QUBO model on your PC/Server, then execute the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ab63d",
   "metadata": {},
   "source": [
    "[INFO]: This could take up to 140 sec for just 1 num_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a623fb",
   "metadata": {},
   "source": [
    "#### Compute using DYNEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22465c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleset = dynexQuboSolution(bqm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e6a83",
   "metadata": {},
   "source": [
    "### Visualize the Optimal Nodes Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateNodes(graph, sampleset):\n",
    "    pos = {node: (data['x'], data['y']) for node, data in graph.nodes(data=True)}\n",
    "    optimalNodes = [node for node, position in sampleset.items() if position == 1]\n",
    "    for node in optimalNodes:\n",
    "        if node not in pos:\n",
    "            print(f\"Node {node} does not have a position in the graph.\")\n",
    "        else:\n",
    "            print(f\"Node {node} is at position {pos[node]} in the graph.\")\n",
    "    return pos, optimalNodes\n",
    "#pos, optimalNodes = validateNodes(graph, sampleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimalNodePositioning(graph, sampleset):\n",
    "    junctionNodes = [node for node, position in sampleset.items() if position == 1]\n",
    "    fig, ax = ox.plot_graph(graph, node_color='black', show=False, close=False)\n",
    "    junctionNodeCoords = [(data['x'], data['y']) for node, data in graph.nodes(data=True) if node in junctionNodes]\n",
    "    for coord in junctionNodeCoords:\n",
    "        ax.scatter(coord[0], coord[1], c='red', s=2, zorder=3)\n",
    "    plt.show()\n",
    "    \n",
    "OptimalNodePositioning(graph, sampleset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b019acc",
   "metadata": {},
   "source": [
    "Now based on the optimal new nodes, we can suggest/create new roads BUT you must consider these factors:\n",
    "- **GIS software**: if we want to implement this example in real-world case, we must collect all the realtime data using GIS software\n",
    "- **Infrastructure**: in Urban planning, we need to have analyze the inftastructure of the city so that we can create/eliminate roads\n",
    "- **Urban Planning Principles**: connectivity, avoiding creation of too many intersections, etc.\n",
    "- **Legal and Environmental Constraints**\n",
    "\n",
    "but nevertheless, this is an educational use case, and it can easily modified for real-world factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewRoads(graph, sampleset, maxDistance=500, newRoads=10):\n",
    "    junctionNodes = [node for node, position in sampleset.items() if position == 1]\n",
    "    potentialNewRoads = []\n",
    "    for i, node1 in enumerate(junctionNodes):\n",
    "        x1, y1 = graph.nodes[node1]['x'], graph.nodes[node1]['y']\n",
    "        for j, node2 in enumerate(junctionNodes):\n",
    "            if i < j: \n",
    "                x2, y2 = graph.nodes[node2]['x'], graph.nodes[node2]['y']\n",
    "                distance = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "                if distance < maxDistance: # for example\n",
    "                    potentialNewRoads.append((node1, node2, distance))\n",
    "    potentialNewRoads.sort(key=lambda x: x[2])\n",
    "    selectedNewRoads = potentialNewRoads[:newRoads] # also for example\n",
    "    for node1, node2, distance in selectedNewRoads:\n",
    "        newRoadAttributes = {\n",
    "            'osmid': -1,  # since I don't know all the OSM IDs\n",
    "            'highway': 'residential', # also for example :)\n",
    "            'length': distance,  # replace with actual length if available\n",
    "            'speed_limit': 30  # replace with actual speed limit if available\n",
    "        }\n",
    "        graph.add_edge(node1, node2, **newRoadAttributes)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be69a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewRoads(graph, sampleset) # I have better way but I'm still working on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ef1e7",
   "metadata": {},
   "source": [
    "### Predicting the new SpeedLimits for the Optimal Nodes Positioning [new nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02290c3a",
   "metadata": {},
   "source": [
    "I know I can come up with better model and more efficient and I apologize for that :\\ \n",
    "    but I will work on it definitely when I'm little bit less busy :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed924a86",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af70519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('speedLimit_.csv')\n",
    "df['SpeedLimit'] = pd.to_numeric(df['SpeedLimit'], errors='coerce')\n",
    "df = df.dropna(subset=['SpeedLimit'])\n",
    "scaler = StandardScaler()\n",
    "df[['x', 'y']] = scaler.fit_transform(df[['x', 'y']])\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "trainX = torch.Tensor(train[['x', 'y']].values)\n",
    "trainY = torch.Tensor(train['SpeedLimit'].values).view(-1, 1)\n",
    "testX = torch.Tensor(test[['x', 'y']].values)\n",
    "testY = torch.Tensor(test['SpeedLimit'].values).view(-1, 1)\n",
    "\n",
    "def augmentation(x, noiseF=0.01):\n",
    "    noise = noiseF * torch.randn(x.size())\n",
    "    augmentation = x + noise\n",
    "    return augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdd7d65",
   "metadata": {},
   "source": [
    "#### Initialize the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64) \n",
    "        self.fc2 = nn.Linear(64, 1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = SPnet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "batch_size = 64\n",
    "trainDataset = TensorDataset(trainX, trainY)\n",
    "trainLoader = DataLoader(dataset=trainDataset, batch_size=batch_size, shuffle=True)\n",
    "trainL = []\n",
    "testL = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e871c46",
   "metadata": {},
   "source": [
    "#### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5000\n",
    "noiseF = 0.01  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38e791",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf33407",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(num_epochs), desc='Epochs')\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    epochTL = 0.0\n",
    "    \n",
    "    for batchX, batchY in trainLoader:  \n",
    "        augBX = augmentation(batchX, noiseF)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(augBX)\n",
    "        loss = criterion(outputs, batchY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epochTL += loss.item() / len(trainLoader)\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputsT = model(testX)\n",
    "        val_loss = criterion(outputsT, testY)\n",
    "    trainL.append(epochTL)\n",
    "    testL.append(val_loss.item())\n",
    "    pbar.set_postfix({'Train Loss': f'{epochTL:.4f}', 'Validation Loss': f'{val_loss.item():.4f}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146af4d",
   "metadata": {},
   "source": [
    "#### Predict the new SpeedLimits based on the Optimal Nodes Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimalNodes = [node for node, position in sampleset.items() if position == 1]\n",
    "\n",
    "nCoords = pd.DataFrame({\n",
    "    'node': optimalNodes,\n",
    "    'x': [graph.nodes[node]['x'] for node in optimalNodes],\n",
    "    'y': [graph.nodes[node]['y'] for node in optimalNodes]\n",
    "})\n",
    "\n",
    "# Normalize the x, y coordinates using the same scaler used during training\n",
    "optimalNodesNorms = torch.Tensor(scaler.transform(nCoords[['x', 'y']]))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    newSpeedLimits = model(optimalNodesNorms)\n",
    "    \n",
    "newSpeedLimits = newSpeedLimits.numpy().flatten().round().astype(int)\n",
    "dic = dict(zip(optimalNodes, newSpeedLimits))\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dec30c",
   "metadata": {},
   "source": [
    "### Visualize the Optimal Nodes with Predicted SpeedLimits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeSpeedLwONoes(graph, speedLimits, sampleset):\n",
    "    pos = {node: (data['x'], data['y']) for node, data in graph.nodes(data=True)}\n",
    "    optimalNodes = [node for node, position in sampleset.items() if position == 1]\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.set_facecolor('black')\n",
    "    for u, v, k, data in graph.edges(keys=True, data=True):\n",
    "        x1, y1 = graph.nodes[u]['x'], graph.nodes[u]['y']\n",
    "        x2, y2 = graph.nodes[v]['x'], graph.nodes[v]['y']\n",
    "        ax.plot([x1, x2], [y1, y2], color='white', linewidth=1, alpha=0.8)\n",
    "    for node in optimalNodes:\n",
    "        if node in speedLimits and node in pos:\n",
    "            speedLimit = speedLimits[node]\n",
    "            if speedLimit <= 20:\n",
    "                color = 'red'\n",
    "            elif 20 < speedLimit <= 30:\n",
    "                color = 'yellow'\n",
    "            else:\n",
    "                color = 'green'\n",
    "            ax.scatter(pos[node][0], pos[node][1], c=color, s=2, zorder=3)\n",
    "    legendElements = [\n",
    "        mlines.Line2D([], [], color='red', marker='o', markersize=5, label='Speed Limit <= 20', linewidth=0),\n",
    "        mlines.Line2D([], [], color='yellow', marker='o', markersize=5, label='20 < Speed Limit <= 30', linewidth=0),\n",
    "        mlines.Line2D([], [], color='green', marker='o', markersize=5, label='Speed Limit > 30', linewidth=0)\n",
    "    ]\n",
    "    ax.legend(handles=legendElements, loc='upper left')\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "visualizeSpeedLwONoes(graph, dic, sampleset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63129e",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6b09b",
   "metadata": {},
   "source": [
    "## EasterEgg [E45T3R3GG] (Optional):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892d711",
   "metadata": {},
   "source": [
    "I taught the machine some secret things that shouldn't be revealed lol\n",
    "but DO NOT make it give you more than 43 secret letters or else...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8e3b6",
   "metadata": {},
   "source": [
    "#### Initialize the ANN and load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E45T3R3GG(secretLetters):\n",
    "    class SamSecretModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SamSecretModel, self).__init__()\n",
    "            self.layers = nn.Sequential(\n",
    "                nn.Linear(1, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1))\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "    model = SamSecretModel()\n",
    "    model.load_state_dict(torch.load('E45T3R3GG.pth'))\n",
    "    model.eval()\n",
    "    x = np.array(list(range(secretLetters)), dtype=np.float32).reshape(-1, 1)\n",
    "    xsc = (x - 0.0) / (288.0 - 0.0)  \n",
    "    xT = torch.from_numpy(xsc).float()\n",
    "    yT = model(xT)\n",
    "    y = np.round(yT.detach().numpy() * (35.0 - 0.0) + 0.0).astype(int)\n",
    "    magic = y.flatten().tolist()\n",
    "    uN = [10609, 19321, 21025, 25600, 26569, 32761, 44521, 49729, 51076, 61009, 64009, 65536,\n",
    "                           71824, 88804, 90601, 92416, 94249, 96100, 97969, 99856, 101761, 103684, 107584, 109561,\n",
    "                           111556, 113569, 115600, 117649, 121801, 123904, 126025, 128164, 130321, 132496, 134689, 136900]\n",
    "    sMessage = ''.join([chr(int((uN[i] ** 0.5) - 7) // 3) for i in magic])\n",
    "    print(sMessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70270dd",
   "metadata": {},
   "source": [
    "#### Execute the E45T3R3GG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "secretLetters = 43              # Keep it 43 to reveal the secret letters :D\n",
    "E45T3R3GG(secretLetters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f4072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
