{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab9797a-d695-430d-9345-801697b584db",
   "metadata": {},
   "source": [
    "# Dynex' Q-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251659e-5210-4332-bb62-437268079178",
   "metadata": {},
   "source": [
    "Q-score measures the efficiency of running a representative quantum application, a system's effectiveness at handling real-life problems, instead of its theoretical or physical performance. [1]. The Q-Score calculation for the Dynex Neuromorphic Computing platform is based by Atos' official package for measuring the Q-Score [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4a16a-07e9-40dc-8a3b-c18a6f3bebd6",
   "metadata": {},
   "source": [
    "In \"Evaluating the Q-score of Quantum Annealers\", Ward van der Schoot et al calculated the Q-Score for a series of D-Wave quantum devices, classical algorithms and hybrid quantum-classical systems. The public Q-Score package [2] has been used to generate the Q-Score for the Dynex Neuromorphic Computing Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c9138-5168-49a6-953b-69dd0c2cd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynex\n",
    "import dimod\n",
    "from pyqubo import Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d50bf1-174a-49a2-8e4a-4b38d755e3b9",
   "metadata": {},
   "source": [
    "### Dynex SDK Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95e0fb-fd5e-42ef-a802-eaf70fb5eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynex.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86123acd-6a98-45a6-b1c3-d745633332a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from dimod import BinaryQuadraticModel, BINARY\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f81a0-ead4-43da-a291-7248ee193496",
   "metadata": {},
   "source": [
    "## Atos Q-Score Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d4eb3-3d21-4e4a-8fbe-6143292195f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sampleset(G, sampleset):\n",
    "    \"\"\"\n",
    "    Function to draw graph 'G' by applying 'sampleset'\n",
    "    \"\"\"\n",
    "    lut = sampleset.first.sample\n",
    "\n",
    "    # Interpret best result in terms of nodes and edges\n",
    "    S0 = [node for node in G.nodes if not lut[node]]\n",
    "    S1 = [node for node in G.nodes if lut[node]]\n",
    "    cut_edges = [(u, v) for u, v in G.edges if lut[u]!=lut[v]]\n",
    "    uncut_edges = [(u, v) for u, v in G.edges if lut[u]==lut[v]]\n",
    "\n",
    "    # Display best result\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=S0, node_color='r')\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=S1, node_color='c')\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=cut_edges, style='dashdot', alpha=0.5, width=3)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=uncut_edges, style='solid', width=3)\n",
    "    nx.draw_networkx_labels(G, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a0ea1-a0dc-4151-905a-b3ace2586b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_job(size, depth = 1, seed=None, plot=False, strength = 10, generate_random = False, debug = False):\n",
    "    \"\"\"\n",
    "    (Re)Implementation of Ato's generate_maxcut_job() function as specified in job_generation.py. It\n",
    "    generates a randum Erdos-Enyi graph of a given size, converts the graph to a QUBO formulation and\n",
    "    returns the two sets as well as the number of cuts (= energy ground state) to be consistent with the paper\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - size (int): size of the maximum cut problem graph\n",
    "    - depth (int): depth of the problem\n",
    "    - seed (int): random seed\n",
    "    - plot (boolean): plot graphs \n",
    "    - strength (int): weight of qubo formulations' edges\n",
    "    - generate_random (boolean): implementation of a random assignment, can replace 0.178 * pow(size, 3 / 2) from paper \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    - Set 0 (list)\n",
    "    - Set 1 (list)\n",
    "    - maximum_cut result (int)\n",
    "    - random_cut result (int)\n",
    "    \"\"\"\n",
    "    # Create a Erdos-Renyi graph of a given size:\n",
    "    G = nx.generators.erdos_renyi_graph(size, 0.5, seed=seed);\n",
    "    if debug:\n",
    "        print('Graph generated. Now constructing Binary Quadratic Model...')\n",
    "    if plot:\n",
    "        nx.draw(G);\n",
    "    \n",
    "    # Convert graph to Qubo \n",
    "    #Q = defaultdict(int)\n",
    "    # Update Q matrix for every edge in the graph\n",
    "    #for i, j in G.edges:\n",
    "    #    Q[(i,i)]+= -1 * strength;\n",
    "    #    Q[(j,j)]+= -1 * strength;\n",
    "    #    Q[(i,j)]+=  2 * strength;\n",
    "    #bqm = dimod.BinaryQuadraticModel.from_qubo(Q, 0.0);\n",
    "    \n",
    "    # we directly build a binary quadratic model (faster):\n",
    "    _bqm = BinaryQuadraticModel.empty(vartype=BINARY);\n",
    "    for i, j in tqdm(G.edges):\n",
    "        _bqm.add_linear(i, -1 * strength);\n",
    "        _bqm.add_linear(j, -1 * strength);\n",
    "        _bqm.add_quadratic(i,j, 2 * strength);\n",
    "        \n",
    "    if debug:\n",
    "        print('BQM generated. Starting sampling...');\n",
    "    \n",
    "    # Sample on Dynex Platform:\n",
    "    model = dynex.BQM(_bqm, logging=False);\n",
    "    sampler = dynex.DynexSampler(model, mainnet=False, description='Dynex Q Score', logging=False);\n",
    "    sampleset = sampler.sample(num_reads=500000, annealing_time = 300, debugging=False);\n",
    "    cut = (sampleset.first.energy * -1 ) / strength;\n",
    "    print('Ground state cut = ',cut);\n",
    "    \n",
    "    # Random cut?\n",
    "    r_cut = -1;\n",
    "    if generate_random:\n",
    "        random_assignment = list(np.random.randint(0, 2, size))\n",
    "        r_assignment = dimod.SampleSet.from_samples_bqm(random_assignment, _bqm)\n",
    "        r_cut = (r_assignment.first.energy * -1 ) / strength;\n",
    "    \n",
    "    if plot:\n",
    "        draw_sampleset(G, sampleset)\n",
    "    \n",
    "    return cut, r_cut\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76662e8c-221a-42cd-be41-0eebb5858884",
   "metadata": {},
   "outputs": [],
   "source": [
    "_NB_INSTANCES_PER_SIZE = 5 #100\n",
    "_INITIAL_SIZE = 5\n",
    "_DEFAULT_SIZE_LIMIT = 20\n",
    "_DEFAULT_DEPTH = 1\n",
    "_DEFAULT_OUT_FILE = \"out.csv\"\n",
    "_DEFAULT_RAW_FILE = \"out.raw\"\n",
    "beta = 0.2\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0345f1c-e289-4ec9-8965-88f06ef8f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_INTRO = \"\"\"=== Running Q-score benchmark | {date} ===\n",
    "Instances size:    {init_size} -- {final_size}\n",
    "Beta:              {beta}\n",
    "Ansatz depth:      {depth}\n",
    "Output file:       {output}\n",
    "Raw output file:   {rawdata}\n",
    "Random seed:       {seed}\n",
    "=================================\"\"\"\n",
    "\n",
    "_HEADER = \"\"\"# Q-Score run | {date}\n",
    "# Instances size:    {init_size} -- {final_size}\n",
    "# Ansatz depth:      {depth}\n",
    "# Beta:              {beta}\n",
    "# Output file:       {output}\n",
    "# Raw output file:   {rawdata}\n",
    "# Random seed:       {seed}\n",
    "# size, avg. score, avg. random score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee53368-dfc3-4f13-b221-0921f2501c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _exhaustive(start_size, end_size):\n",
    "    \"\"\"\n",
    "    Iterates over all the values of the domain until it finds a negative value.\n",
    "    \"\"\"\n",
    "    values = dict()\n",
    "    for index in range(start_size, end_size + 1, 10):\n",
    "        value = yield index\n",
    "        values[index] = value\n",
    "        if value < 0:\n",
    "            if index == start_size:\n",
    "                return False, value, (False, start_size)\n",
    "            return True, values, index - 1\n",
    "    return False, values, (True, max(values), values[max(values)])\n",
    "\n",
    "\n",
    "def _dichotomic(start_size, end_size):\n",
    "    \"\"\"\"\"\"\n",
    "    lower = start_size\n",
    "    upper = end_size\n",
    "    value = yield lower\n",
    "    values = dict()\n",
    "    values[lower] = value\n",
    "    value = yield upper\n",
    "    values[upper] = value\n",
    "\n",
    "    if values[upper] > 0:\n",
    "        return False, values, (True, max(values), values[max(values)])\n",
    "    if values[lower] < 0:\n",
    "        return False, value, (False, start_size)\n",
    "    while True:\n",
    "        if abs(upper - lower) <= 1:\n",
    "            return True, values, lower\n",
    "        next_index = (upper + lower) // 2\n",
    "        values[next_index] = yield next_index\n",
    "        if values[next_index] < 0:\n",
    "            upper = next_index\n",
    "        else:\n",
    "            lower = next_index\n",
    "\n",
    "\n",
    "GENERATORS = {\"exhaustive\": _exhaustive, \"dichotomic\": _dichotomic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefd3cb-bf6d-4505-b849-e07bef618835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver:\n",
    "    \"\"\"\n",
    "    Drives the interaction with an iterator.\n",
    "\n",
    "    Arguments:\n",
    "        fun(callable): the evaluation function.\n",
    "          It should take an index and return a score.\n",
    "        iteration(str): either \"exhaustive\" or \"dichotomic\"\n",
    "        start_size(int): the start size (i.e the lowest index)\n",
    "        end_size(int): the end size (i.e the highest index)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fun, iteration, start_size, end_size):\n",
    "        if iteration not in GENERATORS:\n",
    "            raise ValueError(f\"Unknown iteration method {iteration}\")\n",
    "        self.generator = GENERATORS[iteration](start_size, end_size)\n",
    "        self.fun = fun\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the iteration and returns a tuple containing:\n",
    "        - the success status (True, if an index exists such that f(index) > 0 and f(index + 1) <= 0, False otherwise)\n",
    "        - a map<index, value> containing all the evaluated point\n",
    "        - if found, the index such that f(index) > 0 and f(index + 1) <= 0\n",
    "        \"\"\"\n",
    "        index = next(self.generator)\n",
    "        while True:\n",
    "            try:\n",
    "                index = self.generator.send(self.fun(index))\n",
    "            except StopIteration as exp:\n",
    "                return exp.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e9359-daae-4f40-9ee0-3bd146536fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QScore:\n",
    "    # pylint: disable=too-many-instance-attributes\n",
    "    \"\"\"\n",
    "\n",
    "    Arguments:\n",
    "        qpu(:class:`~qat.core.qpu.QPUHandler`): the QPU to benchmark (including its compilation stack).\n",
    "          The QPU should support variational optimization.\n",
    "        initial_size(int, optional): the initial instance size to try. Default to 5.\n",
    "        size_limit(int, optional): a limit on the size of MAX-CUT instances to try to solve.\n",
    "          Instance sizes will vary from 5 to this limit. Default to 20.\n",
    "        beta(float, optional): the threshold ratio for the test. The official test uses\n",
    "          20% (0.2) as threshold. Default to 0.2\n",
    "        iterator(str, optional): the iteration method to use (\"exhaustive\" or \"dichotomic\").\n",
    "          Default to \"dichotomic\".\n",
    "        depth(int, optional): the QAOA depth to use. Default to 1.\n",
    "        output(str, optional): a file name to store the benchmark output (in CSV format).\n",
    "          Default to out.csv.\n",
    "        rawdata(str, optional): a file name in which to store the raw output of all the runs\n",
    "          performed during the benchmark. Default to out.raw.\n",
    "        seed(int, optional): a seed for the instances generation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        qpu,\n",
    "        size_limit=_DEFAULT_SIZE_LIMIT,\n",
    "        initial_size=_INITIAL_SIZE,\n",
    "        beta=0.2,\n",
    "        iterator= \"exhaustive\", # \"dichotomic\",\n",
    "        depth=_DEFAULT_DEPTH,\n",
    "        output=_DEFAULT_OUT_FILE,\n",
    "        rawdata=_DEFAULT_RAW_FILE,\n",
    "        seed=None,\n",
    "    ):\n",
    "        self._executor = qpu\n",
    "        self._size_limit = size_limit\n",
    "        self._iterator = iterator\n",
    "        self._initial_size = initial_size\n",
    "        self._depth = depth\n",
    "        self._output = output\n",
    "        self._rawdata = rawdata\n",
    "        self._seed = seed if seed is not None else np.random.randint(100000)\n",
    "        self._beta = beta\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the benchmark.\n",
    "        \"\"\"\n",
    "        date_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        print(\n",
    "            _INTRO.format(\n",
    "                date=date_string,\n",
    "                init_size=self._initial_size,\n",
    "                final_size=self._size_limit,\n",
    "                beta=self._beta,\n",
    "                depth=self._depth,\n",
    "                output=self._output,\n",
    "                rawdata=self._rawdata,\n",
    "                seed=self._seed,\n",
    "            )\n",
    "        )\n",
    "        all_data = {}\n",
    "        seed = self._seed\n",
    "        to_output = _HEADER.format(\n",
    "            date=date_string,\n",
    "            init_size=self._initial_size,\n",
    "            beta=self._beta,\n",
    "            final_size=self._size_limit,\n",
    "            depth=self._depth,\n",
    "            output=self._output,\n",
    "            rawdata=self._rawdata,\n",
    "            seed=self._seed,\n",
    "        )\n",
    "\n",
    "        def _evaluate_point(size, seed=seed, to_output=to_output, self=self):\n",
    "            \"\"\"\n",
    "            Function that evaluates a single point.\n",
    "            \"\"\"\n",
    "            print(f\"Running for n={size:2d}.\", end=\" \", flush=True)\n",
    "            scores = []\n",
    "            data = []\n",
    "            for _ in range(_NB_INSTANCES_PER_SIZE):\n",
    "                \n",
    "                #job = generate_maxcut_job(size, self._depth, seed=seed)\n",
    "                #result = self._executor.submit(job)\n",
    "                #result = -cut; # cut is already positive\n",
    "                #scores.append(-result.value)\n",
    "                #data.append({\"seed\": seed, \"score\": -result.value})\n",
    "                #seed += 1\n",
    "                \n",
    "                # the above was replaced with Dynex Sampling function run_job:\n",
    "                cut, r_cut = run_job(size, depth = self._depth, seed=None, plot=False, strength = 1000);\n",
    "                scores.append(cut);\n",
    "                data.append({\"seed\": seed, \"score\": cut})\n",
    "                seed += 1\n",
    "                #print('    cut: ', cut)\n",
    "                \n",
    "            average_score = np.mean(scores) - size * (size - 1) / 8\n",
    "            avg_best_score = 0.178 * pow(size, 3 / 2)\n",
    "            print(f\"Score: {average_score:.2f}.\", end=\" \")\n",
    "            print(f\"Random best score: {avg_best_score:.2f}.\", end=\"\\t\")\n",
    "            to_output = f\"{size},{average_score},{avg_best_score}\\n\"\n",
    "            all_data[size] = data\n",
    "            pickle.dump(all_data, open(self._rawdata, \"wb\"))\n",
    "            with open(self._output, \"a\") as fout:\n",
    "                fout.write(to_output)\n",
    "            achieved_ratio = average_score / avg_best_score\n",
    "            if achieved_ratio > self._beta:\n",
    "                print(\"Success.\", \"beta = \",achieved_ratio)\n",
    "            else:\n",
    "                print(\"Fail.\", \"beta = \", achieved_ratio)\n",
    "            return achieved_ratio - self._beta\n",
    "\n",
    "        success, _, info = Driver(_evaluate_point, self._iterator, self._initial_size, self._size_limit).run()\n",
    "        \n",
    "        print('   ', info)\n",
    "\n",
    "        if success:\n",
    "            print(f\"Success. QScore({self._beta}) = {info}\")\n",
    "        else:\n",
    "            if info[0]:\n",
    "                print(f\"Failure. QScore({self._beta}) > {info[1]}\")\n",
    "                print(\"Maybe try to increase the max instance size !\")\n",
    "            else:\n",
    "                print(f\"Failure. QScore({self._beta}) < {info[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae0f1b-eb06-4beb-80ae-88322e779ea2",
   "metadata": {},
   "source": [
    "# Running Q-Score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9c84c-a830-42c9-ae88-4cddc1bf5450",
   "metadata": {},
   "source": [
    "According to the paper, the Q-Score is defined as the size 'N' at which the beta drops below 0.2. To evaluate this, sizes from 5 to x need to iteratively being tried. Results of all runs are stored in \"out.csv\" which can also be used to plot a chart similar to the ones presented in [1]. The run will return Success for a given value of 'N' until the reached beta falls below the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1c2f8-e416-4d57-a92d-02bd95e3e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "QScore(None, size_limit = 180, depth = 1, output = 'out.csv', rawdata = 'out.raw', seed = 1234).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100eba41-7700-4de2-b457-88aa2878fefc",
   "metadata": {},
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8dc031-ce8a-4576-af3f-86fea437471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('out.csv', names = [\"n\",\"score\",\"random_score\"], header = None)\n",
    "df['beta'] = df['score'] / df['random_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe8a1e-26b0-43f7-9962-611fe829dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(df.n,0.05, width=1, bottom=df.beta-0.025, color='#000000')\n",
    "plt.plot(df['n'], df['beta'], linestyle='None', marker='o')\n",
    "plt.title('Dynex Neuromorphic Platform')\n",
    "plt.xlabel('Problem size N')\n",
    "plt.ylabel('Beta')\n",
    "plt.axhline(y = 0.2, color = 'r', linestyle = '--') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617b88e-7720-4282-8aa5-c0e08305dcb8",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fa6ee-5555-423d-b684-f5b340cb2806",
   "metadata": {},
   "source": [
    "[1] Martiel S, Ayral T, Allouche C. Benchmarking quantum coprocessors in an application-centric, hardware-agnostic, and scalable way. IEEE Transactions on Quantum Engineering. 2021 Jun 17;2:1-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7286fb-2627-4cd5-867f-ce0d93658e40",
   "metadata": {},
   "source": [
    "[2] Atos Package for computing the Atos Q-score: \n",
    "https://github.com/myQLM/qscore/blob/master/qat/qscore/https://github.com/myQLM/qscore/blob/master/qat/qscore/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
