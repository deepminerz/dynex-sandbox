{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882a3df6",
   "metadata": {},
   "source": [
    "# Example: Quantum Deep Learning on Dynex (scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d0516",
   "metadata": {},
   "source": [
    "This examples shows using the Dynex SDK Scikit package which provides a scikit-learn transformer for feature selection using the Dynex Neuromorphic Computing Platform. The number of features have impact on neural network training and accuracy. It will be demonstrated how a significant reduction of features lead to similar (or even better) results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynex\n",
    "import dynex_scikit\n",
    "dynex.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95205b",
   "metadata": {},
   "source": [
    "## Dataset: Breast Cancer Wisconsin "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2412bb7",
   "metadata": {},
   "source": [
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe\n",
    "characteristics of the cell nuclei present in the image.\n",
    "\n",
    "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n",
    "\n",
    "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in:\n",
    "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\",\n",
    "Optimization Methods and Software 1, 1992, 23-34]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78bb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer, y_cancer = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f937f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bb9ef",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d99d47",
   "metadata": {},
   "source": [
    "First we load the required sklearn libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df264d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fea35",
   "metadata": {},
   "source": [
    "Sklearn provides multiple activation functions. We first visualise the different functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea12fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.linspace(-2, 2, 200)\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(xrange, np.maximum(xrange, 0), label = 'relu')\n",
    "plt.plot(xrange, np.tanh(xrange), label = 'tanh')\n",
    "plt.plot(xrange, 1 / (1 + np.exp(-xrange)), label = 'logistic')\n",
    "plt.legend()\n",
    "plt.title('Neural network activation functions')\n",
    "plt.xlabel('Input value (x)')\n",
    "plt.ylabel('Activation function output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67237838",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f58ff7",
   "metadata": {},
   "source": [
    "We have to divide the dataset into training und validation (test) data and are also scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ffc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler();\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print('Training Datapoints: ',len(X_train), 'Validation Datapoints:', len(X_test))\n",
    "print('Features:', X_cancer.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c16da",
   "metadata": {},
   "source": [
    "The original Breast Cancer dataset has 30 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc3400",
   "metadata": {},
   "source": [
    "## Using Dynex SciKit Plugin to reduce the number of features and run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3ce9e",
   "metadata": {},
   "source": [
    "We can run a Quantum algorithm for feature selection to find the relevant features of the breast-cancer dataset. This is being done by calling the Dynex Scikit-Learn plugin \"SelectFromQuadraticModel\" where we can specify the target number of features. We want to reduce the number of features by 33%, leaving only 20 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = dynex_scikit.SelectFromQuadraticModel(num_features=20).fit_transform(X_cancer, y_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcb22e",
   "metadata": {},
   "source": [
    "The variable X_new contains the scikit-learn transformed data and has now 20 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580bb9e",
   "metadata": {},
   "source": [
    "We perform the same training method as above, but with the breast-cancer dataset reduced to 20 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bac3c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_cancer, random_state = 0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = [100, 100], alpha = 5.0,\n",
    "                   random_state = 0, solver='lbfgs').fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530edda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Breast cancer dataset')\n",
    "print('Accuracy of NN classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train_scaled, y_train)))\n",
    "print('Accuracy of NN classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3406c69",
   "metadata": {},
   "source": [
    "The resulting trained model shows less false positives and has similar accuracy values, even though it was trained with just 2/3 of the features from the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e046d19",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "[1] Milne, Andrew, Maxwell Rounds, and Phil Goddard. 2017. \"Optimal Feature Selection in Credit Scoring and Classification Using a Quantum Annealer.\" 1QBit; White Paper. https://1qbit.com/whitepaper/optimal-feature-selection-in-credit-scoring-classification-using-quantum-annealer/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
